# 02. AI를 선택하다 — 판단의 동반자

## 1. 단순 자동화가 아닌 '판단의 도구'

처음부터 우리의 목표는 단순히 알림을 자동으로 읽어주는 시스템이 아니었습니다. 우리가 만들고자 한 것은 판단을 도와주는 AI, 즉 위기 상황 속에서 의사결정을 지원하는 동반자였습니다.

재난 대응의 핵심은 정보 그 자체가 아니라 판단의 속도와 정확성입니다. 따라서 문자형 알림 시스템보다는 맥락형 판단 시스템이 필요하다고 판단했습니다.

## 2. 인간이 흔들릴 때, AI는 냉정하다

실제 재난 상황에서 사람은 생존 본능보다 혼란을 먼저 경험합니다. 그 혼란 속에서 발생하는 인지적 편향(프레이밍, 앵커링, 확증 편향 등)은 오판과 지연으로 이어질 수 있습니다.

우리는 AI가 이러한 심리적 편향을 보정하는 역할을 할 수 있다고 보았습니다. AI는 감정이 아닌 데이터를 기반으로 판단합니다. 즉, AI는 인간이 패닉 상태에 빠졌을 때 냉정함을 유지하며 보조할 수 있는 존재입니다.

## 3. 행동 중심의 AI

기존 LLM 시스템은 대부분 대화형 구조에 머물러 있었습니다. 우리는 LLM을 단순히 대답하는 존재가 아닌, 행동을 유도하는 존재로 재정의하고자 했습니다.

예를 들어, "밖으로 나가세요" 대신 "현재 위치가 3층이라면 계단 이용을 권장합니다. 엘리베이터 사용은 위험할 수 있습니다"라고 제안하거나, "대피하세요" 대신 "건물 오른편 200m 거리에 공원이 있습니다. 이동 시간은 약 1분 정도 예상됩니다"와 같이 사용자의 맥락을 읽고 판단에 필요한 정보를 제공하는 구조를 설계했습니다. 최종 판단과 행동은 항상 사용자의 몫입니다.

## 4. 데이터 연결의 의미

판단의 신뢰성을 높이기 위해 단순 문장 생성이 아닌 다층 데이터 레이어 구조를 도입했습니다.

**문헌 및 RAG 분석 레이어**: 국민행동요령 등 근거를 확보하여 재난 지식을 온톨로지로 체계화한다음 개념 간 관계를 명확히 했습니다.

**실시간 데이터 레이어**: FIRMS(화재 위성정보), 기상청 API, 지역 개방시설 정보 등을 연결합니다.

**LLM 판단 레이어**: 데이터를 조합하여 현재 상황에서 최적의 행동을 산출합니다.

이러한 구조를 통해 AI는 단순한 텍스트 생성이 아닌 사실 기반의 행동 판단을 내릴 수 있었습니다.

## 5. 사람을 대신하지 않고, 사람을 회복시키는 AI

우리가 말하는 AI의 역할은 대체자가 아니라 보조자입니다. AI가 판단을 대신하는 것이 아니라, 판단할 수 있는 여유를 사람에게 돌려주는 것입니다.

사람은 두려움 속에서 냉정해지기 어렵지만, AI는 그 순간을 정리된 정보로 바꿔줄 수 있습니다. 그 한 걸음의 차이가 생명을 지킬 수도 있다는 것을 우리는 여러 시뮬레이션을 통해 체감했습니다.

## 6. 우리가 얻은 확신

AI는 인간보다 똑똑해야 하는 것이 아니라, 인간이 무너질 때 버팀목이 되어야 합니다. 결국 우리가 선택한 이유는 기술이 아니라 철학이었습니다. AI는 판단의 주체가 아니라 생존의 파트너입니다.

이러한 철학이 이후 우리가 시도한 모든 설계의 중심축이 되었습니다. 에이전트 구조, 메모리 시스템, 행동 프롬프트 설계 모두가 이 철학에서 출발했습니다.



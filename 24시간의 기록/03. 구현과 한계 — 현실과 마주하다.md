# 03. 구현과 한계 — 현실과 마주하다

## 1. 시스템 아키텍처

### 멀티 에이전트 구조

우리는 LangChain의 멀티 에이전트 프레임워크를 활용하여 시스템을 설계했습니다. 각 에이전트는 특정 역할을 담당하도록 분리했습니다.

**상황 분석 에이전트**: 사용자의 입력과 맥락 정보를 분석합니다.

**데이터 수집 에이전트**: 필요한 외부 데이터를 수집합니다.

**판단 에이전트**: 수집된 정보를 바탕으로 행동 지침을 생성합니다.

**검증 에이전트**: 생성된 지침의 안전성을 검증합니다.

### RAG 시스템

재난 관련 법령과 행동 매뉴얼을 벡터 데이터베이스에 저장하고, RAG를 통해 관련 정보를 검색하는 구조를 구축했습니다. 「재난 및 안전관리 기본법」, 「자연재해대책법」, 국민행동요령 등을 사용했습니다. 재난-상황-행동의 관계를 온톨로지로 정의하여 AI가 맥락에 맞는 지침을 찾을 수 있도록 했습니다.

### 데이터 통합

기상청 API, FIRMS(NASA 화재 감지), 안전디딤돌 등 여러 공공 API를 연동하려 시도했습니다.

## 2. 부딪힌 현실

### 시간의 벽

해커톤의 현실은 냉정했습니다. 단 24시간 안에 설계도, 데이터, 모델, 시각화까지 모든 것을 동시에 진행해야 했습니다. 우리는 최적화보다 작동을, 완성보다 방향을 우선시했습니다.

### 데이터의 벽

공공데이터 API의 호출 제한, 대피소 좌표의 비일관성, 복잡한 인증 과정 등이 문제였습니다. 하루 안에 모든 데이터를 수집하고 정제할 수 없어, 법령과 행동지침 중심의 정적 판단 모델로 방향을 조정했습니다.

### 기술의 벽

멀티에이전트 구조는 유연하지만, 짧은 시간 안에 메모리, 오케스트레이션, RAG를 안정화시키기 어려웠습니다. 메모리 스토어 초기화 문제, LLM의 맥락 망각 버그 등이 계속 발생했습니다.

문서 청크화 과정에서도 많은 시행착오가 있었습니다. 특히 법령은 조문 간 연관성을 고려하지 않으면 의미가 손실되는 문제가 있었습니다.

### 사람의 벽

밤을 새우며 코드를 작성하다 보니 완성도보다 피로도가 먼저 쌓였습니다. "이 기능은 넣어야 한다"와 "시간 안에 끝낼 수 없다" 사이에서 절충이 더 많았습니다. 기술보다 중요한 것은 같은 방향을 바라보는 팀의 합의였습니다.

## 3. 고민했던 딜레마들

### AI의 판단에 대한 책임

AI가 제공한 행동 지침이 잘못되어 피해가 발생한다면 누가 책임을 져야 할까요? 완전히 해결할 수는 없었지만, AI가 제공하는 모든 판단에 근거를 명시하고 사용자에게 최종 판단권이 있음을 분명히 했습니다.

### 실시간성과 정확성의 균형

빠른 응답과 정확한 판단, 둘 다 중요하지만 때로는 선택해야 했습니다. 기본 지침은 즉시 제공하고, 추가 정보는 순차적으로 보완하는 방식을 택했습니다.

### 전문성과 접근성

전문 용어를 최소화하고, 구체적인 행동 단위로 정보를 제공하는 방식을 선택했습니다. "대피하세요" 대신 "계단으로 1층까지 이동하는 것을 권장합니다"처럼 명확한 안내와 근거를 제공하되, 최종 판단은 사용자가 내리도록 설계했습니다.

### 공포를 줄이는 언어

침착하고 차분한 어조를 유지하면서도, 행동의 우선순위를 명확히 하는 프롬프트 설계에 신경 썼습니다.

## 4. 구체적인 한계들

### 응답 속도

멀티 에이전트 구조와 RAG 검색, LLM 추론이 순차적으로 진행되면서 평균 5~10초의 응답 시간이 필요했습니다. 재난 상황에서는 몇 초의 지연도 치명적일 수 있습니다.

### 에러 핸들링

외부 API 호출 실패, LLM의 예상치 못한 응답, 데이터 형식 오류 등에 대한 대비가 부족했습니다. 시간 제약으로 기본적인 에러 처리만 구현했습니다.

### 확장성

현재 구조는 소수의 사용자를 가정했습니다. 실제 재난 상황에서 수천, 수만 명이 동시 접속하면 시스템이 버티지 못할 것입니다.

### 오프라인 모드

재난 상황에서는 네트워크가 끊길 수 있습니다. 온디바이스 LLM을 활용한 오프라인 모드가 필수적이지만, 해커톤 기간 내에는 구현할 수 없었습니다.

## 5. 포기한 기능들

**음성 인터페이스**: 재난 상황에서 필수적이지만 시간 제약으로 포기했습니다.

**예측 기능**: 앞으로 발생할 수 있는 위험을 예측하는 기능을 고려했으나, 신뢰할 수 있는 모델을 구축하기에는 데이터와 시간이 부족했습니다.

**커뮤니티 기능**: 같은 지역 사용자들의 정보 공유 기능을 구상했으나, 신뢰성 검증과 스팸 방지 메커니즘을 구현할 시간이 없었습니다.

## 6. 남은 질문들

이 프로젝트를 진행하며 우리는 답을 찾은 것보다 더 많은 질문을 발견했습니다.

AI가 생명과 관련된 판단을 내릴 자격이 있는가? 기술이 인간의 본능적 판단을 대체할 수 있는가? 아니면 보완하는 것에 그쳐야 하는가? AI의 판단을 책임질 주체는 누구인가?

이러한 질문들은 하루 안에 답할 수 없는 것들이었습니다. 그러나 이 질문들과 마주한 것 자체가 이 프로젝트의 가치라고 생각합니다.

## 7. 우리가 남긴 문장

기술이 부족해서 멈춘 것이 아니라, 더 깊이 들어가야 할 지점을 발견했기 때문에 멈춘 것입니다.

해커톤의 끝은 완성의 끝이 아니라 탐색의 시작이었습니다. 하루라는 짧은 시간 속에서 AI가 재난 대응에 개입할 수 있는 최소 단위를 찾아낸 것만으로도 이번 도전은 의미가 있었습니다.


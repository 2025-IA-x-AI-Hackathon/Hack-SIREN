# SENSE Backend - ì¬ë‚œ ëŒ€ì‘ í–‰ë™ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ

ì¬ë‚œ ë¬¸ì ë° ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ì—¬ ì¦‰ì‹œ í–‰ë™ ì§€ì¹¨ì„ ì œê³µí•˜ëŠ” ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ì•„í‚¤í…ì²˜

### ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸ (ìˆœì„œ ë³´ì¥)
1. **ProfileAgent**: ì‚¬ìš©ì í”„ë¡œí•„ ë° ìƒí™© ë¶„ì„
2. **PlanningAgent**: ë¶„ì„ ê³„íš ìˆ˜ë¦½
3. **AnalystAgent**: Hybrid RAG ê¸°ë°˜ ì •ë³´ ë¶„ì„
4. **AdvisorAgent**: í–‰ë™ ì§€ì¹¨ ì œì‹œ (immediate/next/caution)

### Hybrid RAG
- **Graph RAG**: Neo4j ê·¸ë˜í”„ DBì—ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ ê²€ìƒ‰
- **Vector RAG**: Chroma ë²¡í„° DBì—ì„œ ë¬¸ì„œ ê²€ìƒ‰

### LLM ì§€ì›
- **Ollama** (ë¡œì»¬ ëª¨ë¸): Gemma3:4b, Qwen3:4b ë“±
- **Gemini** (Google API): gemini-2.0-flash-exp ë“±

## ì„¤ì¹˜

### 1. ì˜ì¡´ì„± ì„¤ì¹˜
```bash
pip install -r ../requirements.txt
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env)
```env
# Neo4j
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# Chroma
CHROMA_PERSIST_DIR=data/chroma
CHROMA_COLLECTION_NAME=disaster_docs

# LLM (Ollama ë˜ëŠ” Gemini ì¤‘ ì„ íƒ)
LLM_PROVIDER=ollama  # ë˜ëŠ” "gemini"
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:4b

# Gemini (LLM_PROVIDER=geminiì¸ ê²½ìš°)
GEMINI_API_KEY=your-api-key
GEMINI_MODEL=gemini-2.0-flash-exp

# API
API_HOST=0.0.0.0
API_PORT=8000
```

### 3. Ollama ì„¤ì • (ë¡œì»¬ ëª¨ë¸ ì‚¬ìš© ì‹œ)
```bash
# Ollama ì„¤ì¹˜ ë° ì‹¤í–‰
curl https://ollama.ai/install.sh | sh
ollama serve

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull gemma3:4b
# ë˜ëŠ”
ollama pull qwen3:4b
```

### 4. Neo4j ë° ë°ì´í„° ì¤€ë¹„
- Neo4j ì‹¤í–‰ (Docker ë˜ëŠ” ë¡œì»¬)
- `3_preprocessing.ipynb` ì‹¤í–‰í•˜ì—¬ Neo4j ë°ì´í„° ì ì¬
- Chroma ì»¬ë ‰ì…˜ì— ë¬¸ì„œ ì ì¬

## ì‹¤í–‰

### API ì„œë²„ ì‹¤í–‰
```bash
# ë°©ë²• 1: ì§ì ‘ ì‹¤í–‰
python -m backend.api

# ë°©ë²• 2: uvicorn ì‚¬ìš©
uvicorn backend.api:app --host 0.0.0.0 --port 8000 --reload

# ë°©ë²• 3: run_server.py ì‚¬ìš© (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ)
python run_server.py
```

### API ì—”ë“œí¬ì¸íŠ¸

#### 1. í—¬ìŠ¤ ì²´í¬
```bash
curl http://localhost:8000/health
```

#### 2. ì¬ë‚œ ë¬¸ì ì²˜ë¦¬
```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "[ê¸´ê¸‰ì¬ë‚œë¬¸ì] ì§€ì§„ ê²½ë³´ ë°œë ¹. ì„œì´ˆêµ¬ ê°•ë‚¨ëŒ€ë¡œ ì§€ì—­ ì£¼ë¯¼ì€ ì¦‰ì‹œ ëŒ€í”¼í•˜ì„¸ìš”.",
    "message_type": "disaster_alert"
  }'
```

#### 3. ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬
```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ê°•ë‚¨êµ¬ì— ìˆëŠ” ëŒ€í”¼ì†ŒëŠ” ëª‡ ê°œì¸ê°€ìš”?",
    "message_type": "user_question",
    "conversation_id": "test-conv-123"
  }'
```

#### 4. ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
```bash
curl http://localhost:8000/conversation/{conversation_id}
```

## ì‘ë‹µ í˜•ì‹

```json
{
  "conversation_id": "uuid",
  "message": "ì‚¬ìš©ì ë©”ì‹œì§€",
  "final_response": "## ğŸš¨ ì¦‰ì‹œ í–‰ë™\n1. ...\n\n## ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„\n1. ...\n\n## âš ï¸ ì£¼ì˜ì‚¬í•­\n1. ...",
  "immediate_actions": ["ì¦‰ì‹œ í–‰ë™ 1", "ì¦‰ì‹œ í–‰ë™ 2"],
  "next_actions": ["ë‹¤ìŒ í–‰ë™ 1", "ë‹¤ìŒ í–‰ë™ 2"],
  "caution_notes": ["ì£¼ì˜ì‚¬í•­ 1", "ì£¼ì˜ì‚¬í•­ 2"],
  "explanation_path": [
    "ProfileAgent: ì‚¬ìš©ì ìƒí™© ë¶„ì„ ê·¼ê±°",
    "PlanningAgent: ë¶„ì„ ê³„íš ê·¼ê±°",
    "AnalystAgent: ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ê·¼ê±°",
    "AdvisorAgent: í–‰ë™ ì§€ì¹¨ ê·¼ê±°"
  ],
  "metadata": {
    "user_profile": {...},
    "analysis_plan": {...},
    "graph_results_count": 10,
    "vector_results_count": 5,
    ...
  }
}
```

## Explainability (ì¶”ë¡  ê·¼ê±°)

ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ì¶”ë¡  ê·¼ê±°ê°€ `explanation_path`ì— ì €ì¥ë©ë‹ˆë‹¤:
- **ProfileAgent**: ì‚¬ìš©ì ìƒí™© ë¶„ì„ ê·¼ê±°
- **PlanningAgent**: ë¶„ì„ ê³„íš ìˆ˜ë¦½ ê·¼ê±°
- **AnalystAgent**: RAG ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ê·¼ê±°
- **AdvisorAgent**: í–‰ë™ ì§€ì¹¨ ìƒì„± ê·¼ê±°

ê° ë‹¨ê³„ì˜ ê·¼ê±°ëŠ” `metadata`ì—ë„ ìƒì„¸ ì •ë³´ê°€ í¬í•¨ë©ë‹ˆë‹¤.

## ëŒ€í™” ê´€ë¦¬

### ë‹¨ì¼ ëŒ€í™”
- `conversation_id`ë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë©´ ìë™ ìƒì„±
- ê° ìš”ì²­ì€ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬

### ë©€í‹°í„´ ëŒ€í™”
- ë™ì¼í•œ `conversation_id`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ì† ëŒ€í™”
- `user_context`ì— ì´ì „ ëŒ€í™” ì •ë³´ í¬í•¨ ê°€ëŠ¥
- ëŒ€í™” íˆìŠ¤í† ë¦¬ëŠ” `/conversation/{conversation_id}`ë¡œ ì¡°íšŒ

## ì½”ë“œ êµ¬ì¡°

```
backend/
â”œâ”€â”€ __init__.py          # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”œâ”€â”€ config.py            # ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ types.py             # íƒ€ì… ì •ì˜ (AgentState, AgentStateModel ë“±)
â”œâ”€â”€ db.py                # DB ì—°ê²° ê´€ë¦¬ (Neo4j, Chroma)
â”œâ”€â”€ llm.py               # LLM í´ë¼ì´ì–¸íŠ¸ (Ollama/Gemini)
â”œâ”€â”€ rag.py               # Hybrid RAG ëª¨ë“ˆ
â”œâ”€â”€ orchestrator.py      # LangGraph ê¸°ë°˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
â”œâ”€â”€ api.py               # FastAPI ì—”ë“œí¬ì¸íŠ¸
â””â”€â”€ agents/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ profile.py       # ProfileAgent
    â”œâ”€â”€ planning.py      # PlanningAgent
    â”œâ”€â”€ analyst.py       # AnalystAgent
    â””â”€â”€ advisor.py        # AdvisorAgent
```

## ì£¼ìš” íŠ¹ì§•

1. **ìˆœì„œ ë³´ì¥**: LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ ì‹¤í–‰ ìˆœì„œ ë³´ì¥
2. **Hybrid RAG**: Graph RAGì™€ Vector RAG ê²°í•©ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ ì œê³µ
3. **Explainability**: ëª¨ë“  ì¶”ë¡  ë‹¨ê³„ì˜ ê·¼ê±° ì¶”ì 
4. **ë©€í‹°í„´ ëŒ€í™”**: ë‹¨ì¼ ë° ë©€í‹°í„´ ëŒ€í™” ëª¨ë‘ ì§€ì›
5. **ì¬ë‚œ ë¬¸ì ì§€ì›**: ì¬ë‚œ ë¬¸ìì™€ ì¼ë°˜ ì§ˆë¬¸ ëª¨ë‘ ì²˜ë¦¬ ê°€ëŠ¥
6. **LLM ìœ ì—°ì„±**: Ollama(ë¡œì»¬) ë˜ëŠ” Gemini(API) ì„ íƒ ê°€ëŠ¥

## ë¬¸ì œ í•´ê²°

### Neo4j ì—°ê²° ì‹¤íŒ¨
- Neo4jê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸: `neo4j status`
- í™˜ê²½ ë³€ìˆ˜ í™•ì¸: `NEO4J_URI`, `NEO4J_USER`, `NEO4J_PASSWORD`

### Chroma ì»¬ë ‰ì…˜ ì—†ìŒ
- `data/chroma` ë””ë ‰í† ë¦¬ í™•ì¸
- `docs/` í´ë”ì˜ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì ì¬ í™•ì¸

### Ollama ì—°ê²° ì‹¤íŒ¨
- Ollama ì‹¤í–‰ í™•ì¸: `ollama serve`
- ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í™•ì¸: `ollama list`
- í™˜ê²½ ë³€ìˆ˜ í™•ì¸: `OLLAMA_BASE_URL`, `OLLAMA_MODEL`

### Gemini API ì˜¤ë¥˜
- API í‚¤ í™•ì¸: `GEMINI_API_KEY`
- ëª¨ë¸ëª… í™•ì¸: `GEMINI_MODEL`
- `LLM_PROVIDER=gemini` ì„¤ì • í™•ì¸

